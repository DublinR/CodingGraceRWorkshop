
\newpage
\chapter{Programming}

%---------------------------------------------------%
\subsubsection{slide234}
The TS are <equation here>  
The p-values for both of these tests are 0 and so there is enough evidence to reject $H_0$ and conclude that both 0 and 1 are not 0, i.e. there is a significant linear relationship between x and y. 
Also given are the $R^2$ and $R^2$ adjusted values. Here $R^2 = SSR/SST = 0.8813$ and so $88.13\%$ of the variation in y is being explained by x. 
The final line gives the result of using the ANOVA table to assess the model t.

%----------------------------------------------------%

\subsubsection{slide235}

In SLR, the ANOVA table tests <EQN>The TS is the F value and the critical value and p-values are found
in the F tables with (p - 1) and (n - p) degrees of freedom.

This output gives the p-value = 0, therefore there is enough evidence to reject H0 and conclude that there is a signicant linear relationship between y and x. The full ANOVA table can be accessed using :

<TABLE HERE>



\subsubsection{slide236}
Once the model has been tted, must then check the residuals.
The residuals should be independent and normally distributed with
mean of 0 and constant variance.
A Q-Q plot checks the assumption of normality (can also use a
histogram as in MINITAB) while a, plot of the residuals versus fitted values gives an indication as to whether the assumption of constant variance holds.

<HISTOGRAM>


%----------------------------------------------------%
\subsubsection{slidename}

\large \begin{verbatim}
> xbar <- 83
> sigma <- 12
> n <- 5
> sem <- sigma/sqrt(n)
> sem
[1] 5.366563
> xbar + sem * qnorm(0.025)
[1] 72.48173
> xbar + sem * qnorm(0.975)
[1] 93.51827
\end{verbatim}\large


\subsubsection{Testing the slope (II)}

You can compute a
t test for that hypothesis simply by dividing the estimate by its standard
error
\begin{equation}
t = \frac{\hat{\beta}}{S.E.(\hat{\beta})}
\end{equation}
which follows a t distribution on n - 2 degrees of freedom if the true $\beta$ is
zero.


%----------------------------------------------------%
\begin{itemize}
*  The standard $\chi^{2}$ test  in chisq.test works with data in matrix form, like fisher.test does.
*  For a 2 by 2 table, the test is exactly equivalent to prop.test.
\end{itemize}


\large \begin{verbatim}
> chisq.test(lewitt.machin)
\end{verbatim}\large

