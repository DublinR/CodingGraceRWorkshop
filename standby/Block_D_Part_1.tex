
### {The R Programming Language}

The R Programming Language is a statistical , data analysis , etc

R is a free software environment for statistical computing and graphics.

<p>
### {Writing R scripts}
Editing your R script ``R Editor".

On the menu of the R console, click on file.
Select open script or new script as appropriate.
Navigate to your working directory and select your texttt{.R} file
A new dialogue box ``texttt{the R editor}" will open up.
Input or select code you wish to compile.
To compile this code, highlight it. Click the edit button on the menu.
Select either ``Run Line" or ``Run Selection or All".
Your code should now compile.
To save your code, clink on ``file" and then ``texttt{save as}".
Save the file with the ``texttt{.R}" extension to your working directory.




#### {Reading data}


<p>
#### {inputting data}
 Concatenation

<p>
#### {using help}

?mean

%<p>
#### {Adding comments}

<p>
#### {Packages}
The capabilities of R are extended through user-submitted packages, which allow specialized statistical techniques, graphical devices, as well as and
import/export capabilities to many external data formats.


<p>
#### {Data frame}
A Data frame is





<p>
### {Bivariate Data}
 begin{myindentpar}{1cm}
<code>
> Y=mtcars$mpg
> X=mtcars$wt
>
> cor(X,Y)   #Correlation
[1] -0.8676594
>
> cov(X,Y)   #Covariance
[1] -5.116685
</code>
end{myindentpar}


<p>
### {Histograms}
Histograms can be created using the texttt{hist()} command.
To create a histogram of the car weights from the Cars93 data set

begin{myindentpar}{1cm}
<code>
hist(mtcars$mpg, main="Histogram of MPG (Data: MTCARS) ")
</code>
end{myindentpar}
texttt{R} automatically chooses the number and width of the bars. We can
change this by specifying the location of the break points.

begin{myindentpar}{1cm}
<code>hist(Cars93$Weight, breaks=c(1500, 2050, 2300, 2350, 2400,
2500, 3000, 3500, 3570, 4000, 4500), xlab="Weight",
main="Histogram of Weight")
</code>
end{myindentpar}



<p>
### {Boxplot}
Boxplots can be used to identify outliers.

By default, the texttt{boxplot()} command sets the orientation as vertical. By adding the argument texttt{horizontal=TRUE}, the orientation can be changed to horizontal.

begin{myindentpar}{1cm}
<code>
boxplot(mtcars$mpg, horizontal=TRUE, xlab="Miles Per Gallon",
main="Boxplot of MPG")
</code>
end{myindentpar}

begin{figure}
  % Requires usepackage{graphicx}
  includegraphics[scale=0.4]{MTCARSboxplot.png}
  caption{Boxplot}label{boxplot}
end{figure}




chapter{Advanced R code}
<p>
### {Data frame}
A Data frame is
<p>
#### {Merging Data frames}

<p>
### {Functions}
Syntax to define functions

begin{myindentpar}{1cm}
<code>
 myfct <- function(arg1, arg2, ...) { function_body }
</code>
end{myindentpar}
The value returned by a function is the value of the function body, which is usually an unassigned final expression, e.g.: return()

Syntax to call functions
begin{myindentpar}{1cm}
<code>
 myfct(arg1=..., arg2=...)
</code>
end{myindentpar}


<p>
### {Time and Date}
It is useful . The length of time a program takes is interesting.


begin{myindentpar}{1cm}
<code>
date() # returns the current system date and time
</code>
end{myindentpar}


<p>
### {The Apply family}

Sometimes want to apply a function to each element of a
vector/data frame/list/array.

Four members: lapply, sapply, tapply, apply

lapply: takes any structure and gives a list of results (hence
the `l')

sapply: like lapply, but tries to simplify the result to a
vector or matrix if possible (hence the `s')

apply: only used for arrays/matrices

tapply: allows you to create tables (hence the `t') of values
from subgroups defined by one or more factors.

chapter{Data Visualization}
<p>
### {Plots}
This <p>
###  is an introduction for producing simple graphs with
the R Programming Language.

Line Charts  Bar Charts Histograms Pie
Charts Dotcharts



#### {Comparison of variances}


Even though it is possible in R to perform the two-sample t test without
the assumption that the variances are the same, you may still be interested
in testing that assumption, and R provides the var.test function for that
purpose, implementing an F test on the ratio of the group variances. It is
called the same way as texttt{t.test}:.
<code>
> var.test(expend~stature)
</code>

      
      

 <code>
> code here
 </code>


<p>
#### { Charts}

begin{myindentpar}{1cm}
<code>
# Define 2 vectors cars <- c(1, 3, 6, 4, 9) trucks <- c(2, 5, 4,
5, 12)

# Calculate range from 0 to max value of cars and trucks g_range
<- range(0, cars, trucks)

# Graph autos using y axis that ranges from 0 to max # value in
cars or trucks vector.  Turn off axes and # annotations (axis
labels) so we can specify them ourself plot(cars, type="o",
col="blue", ylim=g_range,
   axes=FALSE, ann=FALSE)

# Make x axis using Mon-Fri labels axis(1, at=1:5,
lab=c("Mon","Tue","Wed","Thu","Fri"))

# Make y axis with horizontal labels that display ticks at # every
4 marks. 4     0:g_range[2] is equivalent to c(0,4,8,12). axis(2,
las=1, at=4     0:g_range[2])

# Create box around plot box()

# Graph trucks with red dashed line and square points
lines(trucks, type="o", pch=22, lty=2, col="red")

# Create a title with a red, bold/italic font title(main="Autos",
col.main="red", font.main=4)

# Label the x and y axes with dark green text title(xlab="Days",
col.lab=rgb(0,0.5,0)) title(ylab="Total", col.lab=rgb(0,0.5,0))

# Create a legend at (1, g_range[2]) that is slightly smaller #
(cex) and uses the same line colors and points used by # the
actual plots legend(1, g_range[2], c("cars","trucks"), cex=0.8,
   col=c("blue","red"), pch=21:22, lty=1:2);

</code>
end{myindentpar}
<p>
#### {Bar charts}
begin{myindentpar}{1cm}
<code>
# Define the cars vector with 7 values
cars <- c(1, 3, 6, 4, 9, 5, 7)
# Graph cars
barplot(cars)
</code>
end{myindentpar}
<p>
#### {Boxplots}
<p>
#### {Setting graphical parameters}
<p>
#### {Miscellaneous}
The following code can be used to make variations of the plots.

begin{myindentpar}{1cm}
 <code>
# Make an empty chart
plot(1, 1, xlim=c(1,5.5), ylim=c(0,7), type="n", ann=FALSE)

# Plot digits 0-4 with increasing size and color
text(1:5, rep(6,5), labels=c(0:4), cex=1:5, col=1:5)

# Plot symbols 0-4 with increasing size and color
points(1:5, rep(5,5), cex=1:5, col=1:5, pch=0:4)
text((1:5)+0.4, rep(5,5), cex=0.6, (0:4))

# Plot symbols 5-9 with labels
points(1:5, rep(4,5), cex=2, pch=(5:9))
text((1:5)+0.4, rep(4,5), cex=0.6, (5:9))

# Plot symbols 10-14 with labels
points(1:5, rep(3,5), cex=2, pch=(10:14))
text((1:5)+0.4, rep(3,5), cex=0.6, (10:14))

# Plot symbols 15-19 with labels
points(1:5, rep(2,5), cex=2, pch=(15:19))
text((1:5)+0.4, rep(2,5), cex=0.6, (15:19))

# Plot symbols 20-25 with labels
points((1:6)     0.8+0.2, rep(1,6), cex=2, pch=(20:25))
text((1:6)     0.8+0.5, rep(1,6), cex=0.6, (20:25))
</code>
end{myindentpar}

<p>
#### {Lattice Graphs}
<p>
#### {setting up}
Execute the following command:
begin{myindentpar}{1cm}
<code>
library(lattice)
</code>
end{myindentpar}
For information on lattice, type:
begin{myindentpar}{1cm}
<code>
help(package = lattice)
</code>
end{myindentpar}
The examples in this <p>
###  are generally drawn from the R documentation and Murrell (2006).

Murrell gives three reasons for using Lattice Graphics:

They usually look better.
They can be extended in powerful ways.
The resulting output can be annotated, edited, and saved

<p>
#### {3 Dimensional Graphs}
How to do a 3-d graph


chapter{Statistical Analysis using R}
<p>
### {Confidence Intervals}
<p>
#### {Confidence Intervals for Large Samples}
<p>
#### {Confidence Intervals for Small Samples}

<p>
### {Linear Models}

The Slope and Intercept
begin{myindentpar}{1cm}
<code>

</code>
end{myindentpar}

<p>
### {ANOVA}


%--------------------------------------------------------Inference Procedures and testing for Normality-%

%chapter{Normality Assumptions and Outliers}
%
#### {Grubbs Test for outliers}
%<p>
#### {Anderson Darling Test}
%<p>
#### {Normal Probability plots}
%
#### { Kolmogorov Smirnov Test}





<p>
#### {Subsetting datasets by rows}

Suppose we wish to divide a data frame into two different <p>
### . The simplest approach we can take is to create two new data sets, each assigned data from the relevant rows of the original data set.

Suppose our dataset ``Info" has the dimensions of 200 rows and 4 columns. We wish to separate "Info" into two subsets , with the first and second 100 rows respectively. ( We call these new subsets "Info.1" and "Info.2".)
<code>
Info.1 = Info[1:100,]		#assigning "info" rows 1 to 100
Info.2 = Info[101:200,]		#assigning "info" rows 101 to 200
</code>

More useful commands such as rbind() and cbind()  can be used to manipulate vectors.

Part 2 Strategies for Data project

Exploratory Data Analysis

The first part of your report should contain some descriptive statistics and summary values. Also include some tests for normality.

      {Regression}
You should have a data set with multiple columns, suitable for regression analysis.
Familiarize yourself with the data, and decide which variable is the dependent variable.

Also determine the independent variables that you will use as part of your analysis.

      {Correlation Analysis}
Compute the Pearson correlation for the dependent variable with the respective independent variables.  As part of your report, mention the confidence interval for the correlation estimate
Choose the independent variables with the highest correlation as your candidate variables.
For these independent variables, perform a series of simple linear regression procedures.
<code>
lm(y~x1)
lm(y~x2)
</code>
Comment on the slope and intercept estimates and their respective p-values. Also comment on the coefficient of determination (multiple R squared). Remember to write the regression equations.
Perform a series of multiple linear regressions, using pairs of candidate independent variables.
<code>
lm(y~x1 +x2)
lm(y~x2 +x3)
</code>
Again, comment on the slope and intercept estimates, and their respective p-values.
In this instance, compare each of the models using the coefficient of determinations. Which model explains the data best?
<p>
#### {Analysis of residuals}
Perform an analysis of regression residuals ( you can pick the best regression model from last <p>
### ).
Are the residuals normally distributed?
	Histogram /  Boxplot / QQ plot / Shapiro Wilk Test
Also you can plot the residuals to check that there is constant variance.
<code>
y=rnorm(10)
x=rnorm(10)
fit1=lm(y~x)
res.fit1 = resid(fit1)
plot(res.fit1)
</code>




<p>
### {Combining plots}
It is possible to combine two plots. We used the graphical parameters command texttt{par()} to create an array. 
Often we just require two plots side by side or above and below. We simply specify the numbers of rows and columns of this array using the texttt{mfrow} argument, passed as a vector.

<code>
par(mfrow=c(1,2))
plot(x,y1)			# draw first plot
plot(x,y2)			# draw second plot
par(mfrow=c(1,1))		# reset to default setting.
</code>

<p>
### {Plot of single vectors}
If only one vector is specified i.e. texttt{plot(x)},  the plot created will simply be a scatter-plot of the values of x against their indices.

$plot(x)$
Suppose we wish to examine a trend that these points represent. We can connect each covariate using a line.

$plot(x, type = "l")$
If we wish to have both lines and points, we would input the following code. This is quite useful if we wish to see how a trend develops over time.
$plot(x, type = "b")$









<p>
### {Exercise} The following are measurements (in mm) of a critical
dimension on a sample of twelve engine crankshafts:

<code>
224.120 	224.001 	224.017 	223.982 	223.989 	223.961
223.960 	224.089 	223.987 	223.976 	223.902 	223.980
</code>
(a) Calculate the mean and standard deviation for these data.
(b) The process mean is supposed to be ? = 224mm. Is this the
case? Give reasons for your answer.
(c) Construct a 99% confidence interval for these data and interpret.
(d) Check that the normality assumption is valid using 2 suitable plots.

<code>
> x<-c(224.120,224.001,224.017,223.982 ,223.989 ,223.961,
+ 223.960 ,224.089 ,223.987 ,223.976 , 223.902 ,223.980)
>
> mean(x)
[1] 223.997
>
> sd(x)
[1] 0.05785405
>
> t.test(x,mu=224,conf.level=0.99)

 One Sample t-test

data:  x
t = -0.1796, df = 11, p-value = 0.8607
alternative hypothesis: true mean is not equal to 224
99 percent confidence interval:
 223.9451 224.0489
sample estimates:
mean of x
  223.997

</code>
<p>
### {Exercise 2} 
The height of 12 Americans and 10 Japanese was measured. Test for a difference in the heights of both populations.
<code>
Americans
174.68   	169.87 	   	165.07    	165.95 		204.99 		177.61 	
170.11 	 	170.71 	   	181.52 		167.68 		158.62 		182.90
Japanese
158.76  		168.85  		159.64  		180.02  		164.24
161.91  		163.99  		152.71  		157.32  		147.20
</code>


<p>
### {Exercise 3}

A large group of students each took two exams. The marks obtained in both exams by a sample of eight students is given below

<code>
Student	1	2	3	4	5	6	7	8
Exam 1	57	76	47	39	62	56	49	81
Exam 2	67	81	62	49	57	61	59	71
</code>
Test the hypothesis that in the group as a whole the mean mark gained did not vary according to the exam against the hypothesis that the mean mark in the second exam was higher
<code>
>
> Ex1<-c(57,76,47,39,62,56,49,81)
> Ex2<-c(67,81,62,49,57,61,59,71)
> t.test(Ex1-Ex2)

 One Sample t-test

data:  Ex1 - Ex2
t = -1.6733, df = 7, p-value = 0.1382
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 -12.065666   2.065666
sample estimates:
mean of x
-5
</code>

<p>
### {Exercise 4}
A poll on social issues interviewed 1025 people randomly selected from the United States. 450 of people said that they do not get enough time to themselves. A report claims that over 41% of the population are not satisfied with personal time. Is this the case?

<code>

> prop.test(450,1025,p=0.40,alternative="greater")

 1-sample proportions test with continuity correction

data:  450 out of 1025, null probability 0.4
X-squared = 6.3425, df = 1, p-value = 0.005894
alternative hypothesis: true p is greater than 0.4
95 percent confidence interval:
 0.413238 1.000000
sample estimates:
 p
0.4390244
</code>

Exercise 23b:  A company wants to investigate the proportion of males and females promoted in the last year. 45 out of 400 female candidates were promoted, while 520 out of 3270 male candidates were promoted. Is there evidence of sexism in the company?
<code>
> x.vec=c(45,520)
> n.vec=c(400,3270)
>  prop.test(x.vec,n.vec)

 2-sample test for equality of proportions with continuity correction

data:  x.vec out of n.vec
X-squared = 5.5702, df = 1, p-value = 0.01827
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.08133043 -0.01171238
sample estimates:
   prop 1    prop 2
0.1125000 0.1590214
</code>

?
<p>
### {Exercise}

Generate a histogram for data set 'scores', with an accompanying box-and-whisker plot.
The colour of the histogram's bar should be yellow. The orientation for the boxplot should be horizontal.

<code>
scores <-c(23,19,22,22,19,20,25,26,26,19,24,23,17,21,28,26)

par(mfrow=c(2,1)) 	# two rows , one column

hist(scores,main="Distribution of scores",xlab="scores",col="yellow")

boxplot(scores ,horizontal=TRUE)

par(mfrow =c(1,1)) 	#reset
</code>
<p>
### {The R Programming Language}

The R Programming Language is a statistical , data analysis , etc

R is a free software environment for statistical computing and graphics.

<p>
### {Writing R scripts}
Editing your R script ``R Editor".

On the menu of the R console, click on file.
Select open script or new script as appropriate.
Navigate to your working directory and select your texttt{.R} file
A new dialogue box ``texttt{the R editor}" will open up.
Input or select code you wish to compile.
To compile this code, highlight it. Click the edit button on the menu.
Select either ``Run Line" or ``Run Selection or All".
Your code should now compile.
To save your code, clink on ``file" and then ``texttt{save as}".
Save the file with the ``texttt{.R}" extension to your working directory.


<p>
### {Vector types}
texttt{R} operates on named data structures. The simplest such structure is the
vector, which is a single entity consisting of an ordered collection of
Numbers or characters.


Numeric vectors
Character vectors
Logical vectors
(also complex number vectors and colour vectors)


To create a vector, use the assignment operator and the concatenate function.
For numeric vectors, the values are simply numbers.

<code>
># week8.r
>NumVec<-c(10.4,5.6,3.1,6.4)
</code>

Alternatively we can use the texttt{assign()} command

For character vectors, the values are simply characters, specified with
quotation marks.A logical vectors is a vector whose elements are TRUE, FALSE or NA

<code>
>CharVec<-c(``blue", ``green", ``yellow")
>LogVec<-c(TRUE, FALSE)
</code>

<p>






%----------------------------------------------------------------%
<p>
### {Some Useful Operations}
<p>
#### {Sampling}

The texttt{sample()} function.

<p>
#### {Set Theory Operations}

<p>
#### {Controlling Precision and Integerization}
<pre>
<code>
pi
round(pi,3)
round(pi,2)
floor(pi)
ceiling(pi)
</code>
</pre>
<p>

%----------------------------------------------------------------%

<p>
### {Important Introductory Topics}
<p>
#### {The texttt{head()} and texttt{tail()} functions}
<p>
#### {Randomly Generated Numbers}
With $a$ and $b$ as the lower and upper bound of the continous uniform distribution.
[X sim U(a,b)]
<p>
#### {The texttt{as} and texttt{is} families of functions}
<p>
#### {The texttt{apply} family of functions}
<p>
#### {Writing your own function}


%----------------------------------------------------------------%
<p>
### {Lists and Data Frames}
<p>
#### {Lists}
<p>
#### {Named Components}
<p>
#### {Data Frames}
<pre>
<code>
framename = data.frame()
</code>
</pre>
<p>
%----------------------------------------------------------------%
<p>
### {Important Graphical Procedures}
begin{enumerate}
Histograms
Box-plots
Scatter-plots
end{enumerate}


%----------------------------------------------------------------%

<p>
#### {Correlation  and Regression tests }

#### {Correlation Coefficient}
Strength of a linear relationship between $X$ and $Y$

%<pre>
<code>
M=1000
CorrData=numeric(M)
for (i in 1:M)
{
CorrData[i] = cor(rnorm(10),rnorm(10))
}
</code>
%</pre>
<p>
The null hypothesis is that the correlation coefficient is zero. 

The alternative hypothesis is that the correlation coefficients is greater than zero. 

The slope and intercept estimates 

These tests are given in the "Two Tailed" format. 
The one tailed format compares a null hypothesis where the parameter of interest has a true value of less than or equalt to one versus an alternative hypothesis stating that it has a value greater than zero. 
  



<p>
### {Programming Paradigms}
<p>
#### {While Loops}
The while loop can be used if the number of iterations required is not known beforehand. For example, if we want to continue looping until a certain condition is met, a while loop is useful.

The following is the syntax for a while loop:

<code>
while (condition){
   command
   command
}
</code>
The loop continues while texttt{condition == TRUE}.


Note: texttt{sample()} takes a sample of the specified size (here just one) from a range of values (here integers 1 to 100).
<pre>
<code>

#initialise a counter to zero
niter = 0		
#initialize an empty vector
numvec = numeric()


num = sample(1:100, 1)

#while loop
while(num != 20)
   {
   num = sample(1:100, 1)
   niter = niter + 1
   numvec = c(numvec,num)
   }
numvec
niter

</code>
</pre>
<p>


<p>
#### {Nested Loops}

<p>
#### {Sums of two dice rolls}
<pre>
<code>
#Set Up an Empty Matrix of 6 rows and 6 columns
Dice = matrix(0,6,6)

#Main Loop
for(i in 1:6)
	{
    #Nested Loop
	for(j in 1:6)
		{
		Dice[i,j] = i+j
		}
	}		
Dice   # Print your Results
</code>
</pre>
<p>
<p>
#### {Correlation Structure Example}



<p>
### {Correlation and Simple Regression Models}

<p>
#### {Correlation}

A correlation coefficient is a number between -1 and 1 which measures the degree to which two variables are linearly related. If there is perfect linear relationship with positive slope between the two variables, we have a correlation coefficient of 1; if there is positive correlation, whenever one variable has a high (low) value, so does the other.

If there is a perfect linear relationship with negative slope between the two variables, we have a correlation coefficient of -1; if there is negative correlation, whenever one variable has a high (low) value, the other has a low (high) value.
A correlation coefficient of 0 means that there is no linear relationship between the variables.

We can determine the Pearson Correlation coefficient in R using the texttt{cor()} command.
To get a more complete statistical analysis, with formal tests, we can use the command texttt{cor.test()}
The interpretation of the output from the cor.test()procedure is very similar to procedures we have already encountered. The null hypothesis is that the correlation coefficient is equal to zero. This is equivalent to saying that there is no linear relationship between variables.


<pre>
<code>
C=c(0,2,4,6,8,10,12) 
F=c(2.1,5.0,9.0,12.6,17.3,21.0,24.7)
cor.test(C,F)
</code>
</pre>
<p>
<code>

 Pearson's product-moment correlation

data:  C and F 
t = 47.1967, df = 5, p-value = 8.066e-08
alternative hypothesis: true correlation is not equal to 0 
95 percent confidence interval:
 0.9920730 0.9998421 
sample estimates:
      cor 
0.9988796 
</code>


<p>
#### {Spearman and Kendall Correlation}
Spearman and Kendall correlations are both textbf{emph{rank correlations}}. 
To implement Spearman and Kendall correlation, simply specify the type in the texttt{method=" "} argument.
<code>
> cor(G,D)
[1] 0.3167869
>
> cor(G,D,method="spearman")
[1] 0.1785714
>
> cor(G,D,method="kendall")
[1] 0.1428571
> 
</code>
The interpretation is very similar, but there are no confidence intervals for the estimates.

<p>
#### {Fitting a Regression Model}
A regression model is fitted using the texttt{lm()} command.

Consider the response variable $F$ and predictor variable $C$.
<pre>
<code>
C=c(0,2,4,6,8,10,12) 
F=c(2.1,5.0,9.0,12.6,17.3,21.0,24.7)
Fit1=lm(F~C)
</code>
</pre>
<p>


<p>
#### {Confidence and Prediction Intervals for Fitted Values} 

Recall that a fitted value $hat{Y}$ is a estimate for the response variable, as determined by a linear model. The difference between the observed value and the corresponding fitted value is known as the residual.

The textbf{emph{residual standard error}} is the conditional standard deviation of the dependent variable Y given a value of the independent variable X. The calculation of this standard error follows from the definition of the residuals.

The residual standard error is often called the root mean square error (RMSE), and is a measure of the differences between values predicted by a model or an estimator and the values actually observed from the thing being modelled or estimated.

Since the residual standard error is a good measure of accuracy, it is ideal if it is small.


#### {Prediction Intervals}
In contrast to a confidence interval, which is concerned with estimating a population parameter, a prediction interval is concerned with estimating an individual value and is therefore a type of probability interval. 

The complete standard error for a prediction interval is called the standard error of forecast, and it includes the uncertainty associated with the vertical “scatter” about the regression line plus the uncertainty associated with the position of the regression line value itself.










%----------------------------------------------------------------------------------------------------------------------------%
<p>
### {Working with Categorical Data}
<p>
#### {Chi-Square}

The table below shows the relationship between gender and party identification in a US state.


%	   & Democrat &	Independent & Republican & Total 
%Male   &	279	& 73  &	225 &	577 
%Female &	165	& 47  & 191 &	403 
%Total  &	444 & 120 &	416	&   980 

Test for association between gender and party affiliation at two appropriate levels
and comment on your results.

Set out the null hypothesis that there is no association between method of computation
and gender against the alternative, that there is. Be careful to get these the correct way
round!

H0: There is no association.
H1: There is an association.

Work out the expected values. For example, you should work out the expected value for
the number of males who use no aids from the following: (95/195) × 22 = 10.7.


<p>
### {Probability Distributions}
<p>
#### {Discrete Probability Distribution}


The two most accessible discrete distributions are the binomial and textbf{emph{Poisson}} distributions


